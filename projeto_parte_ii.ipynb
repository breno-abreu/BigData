{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e38d59a9-73ce-4660-b6ca-b22b758dbb77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.sql.types import StringType, StructType, StructField\n",
    "\n",
    "\n",
    "# Cria uma sess√£o Spark habilitando Hive support para armazenar dados no Spoark Warehouse\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"projeto_parte_ii\") \\\n",
    "    .config('spark.master', 'local') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5773ff6c-e806-4b05-b9b1-0f0d25dca29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 20:39:19 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/06/11 20:39:19 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark read Hive table\n",
    "spark.sql(\"USE projeto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfdccecb-c70c-474b-8c07-70e1ef4209e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nf_numero: string (nullable = true)\n",
      " |-- nf_data_emissao: date (nullable = true)\n",
      " |-- nf_valor_total: decimal(15,2) (nullable = true)\n",
      " |-- emit_cnpj: string (nullable = true)\n",
      " |-- emit_cep: string (nullable = true)\n",
      " |-- emit_municipio: string (nullable = true)\n",
      " |-- dest_cnpj: string (nullable = true)\n",
      " |-- dest_cep: string (nullable = true)\n",
      " |-- dest_municipio: string (nullable = true)\n",
      " |-- prod_nr_item: integer (nullable = true)\n",
      " |-- prod_cod: string (nullable = true)\n",
      " |-- prod_desc: string (nullable = true)\n",
      " |-- prod_ncm: string (nullable = true)\n",
      " |-- prod_valor_unit: decimal(15,2) (nullable = true)\n",
      " |-- ano: integer (nullable = true)\n",
      " |-- nome_regiao: string (nullable = true)\n",
      " |-- sigla_uf: string (nullable = true)\n",
      " |-- nome_municipio: string (nullable = true)\n",
      " |-- nome_mesoregiao: string (nullable = true)\n",
      " |-- nome_microregiao: string (nullable = true)\n",
      " |-- tipologia_rural_urbana: string (nullable = true)\n",
      " |-- hierarquia_urbana: string (nullable = true)\n",
      " |-- pop: integer (nullable = true)\n",
      " |-- pib: decimal(15,2) (nullable = true)\n",
      " |-- pop_meso: long (nullable = true)\n",
      " |-- pib_meso: decimal(25,2) (nullable = true)\n",
      " |-- prod_unid_nn: string (nullable = true)\n",
      " |-- prod_quant_nn: decimal(19,6) (nullable = true)\n",
      " |-- prod_valor_unit_nn: decimal(19,6) (nullable = true)\n",
      " |-- prod_valor_total_nn: decimal(38,11) (nullable = true)\n",
      " |-- log_prod_quant: double (nullable = true)\n",
      " |-- log_prod_valor_unit: double (nullable = true)\n",
      " |-- scaled_log_prod_quant: double (nullable = true)\n",
      " |-- scaled_log_prod_valor_unit: double (nullable = true)\n",
      " |-- scaled_pop_meso: double (nullable = true)\n",
      " |-- scaled_pib_meso: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM notas_fiscais WHERE prod_unid_nn IN ('und', 'kg', 'cx', 'pacote', 'l')\")\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d82029b-f397-44de-b89e-20608058d85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- prod_ncm: string (nullable = true)\n",
      " |-- prod_unid: string (nullable = true)\n",
      " |-- prod_quant: double (nullable = true)\n",
      " |-- prod_valor_unit: decimal(15,2) (nullable = true)\n",
      " |-- reg_mesoregiao: string (nullable = true)\n",
      " |-- reg_tipologia: string (nullable = true)\n",
      " |-- reg_hierarquia: string (nullable = true)\n",
      " |-- reg_pop: double (nullable = true)\n",
      " |-- reg_pib: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_keep = '''\n",
    "prod_ncm, \n",
    "prod_unid_nn as prod_unid, \n",
    "scaled_log_prod_quant as prod_quant, \n",
    "prod_valor_unit as prod_valor_unit,\n",
    "nome_mesoregiao as reg_mesoregiao, \n",
    "tipologia_rural_urbana as reg_tipologia, \n",
    "hierarquia_urbana as reg_hierarquia, \n",
    "scaled_pop_meso as reg_pop,\n",
    "scaled_pib_meso as reg_pib\n",
    "'''\n",
    "\n",
    "df = spark.sql(f\"SELECT {columns_to_keep} FROM notas_fiscais\")\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb886711-681a-4a5a-8189-d22c1a48599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|prod_unid|\n",
      "+---------+\n",
      "|        l|\n",
      "|      und|\n",
      "|       cx|\n",
      "|       kg|\n",
      "|   pacote|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(f\"SELECT * FROM df WHERE prod_unid IN ('und', 'kg', 'cx', 'pacote', 'l')\")\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "select = spark.sql(\"SELECT DISTINCT prod_unid FROM df\")\n",
    "select.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdf8b6b8-e4b1-40a8-bf16-44da24bf5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2697ca98-d111-4d00-98fb-5d9c470b85b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# prod_ncm\n",
    "'''indexer = StringIndexer(inputCol=\"prod_ncm\", outputCol=\"prod_ncm_indexed\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"prod_ncm_indexed\", outputCol=\"prod_ncm_onehot\")\n",
    "df = encoder.fit(df).transform(df)'''\n",
    "\n",
    "df = df.withColumn(\"prod_ncm\", df[\"prod_ncm\"].cast(IntegerType()))\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "df = spark.sql(\"SELECT * FROM df WHERE prod_ncm IS NOT NULL\")\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "#prod_unid\n",
    "indexer = StringIndexer(inputCol=\"prod_unid\", outputCol=\"prod_unid_indexed\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"prod_unid_indexed\", outputCol=\"prod_unid_onehot\")\n",
    "df = encoder.fit(df).transform(df)\n",
    "\n",
    "#reg_mesoregiao\n",
    "indexer = StringIndexer(inputCol=\"reg_mesoregiao\", outputCol=\"reg_mesoregiao_indexed\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"reg_mesoregiao_indexed\", outputCol=\"reg_mesoregiao_onehot\")\n",
    "df = encoder.fit(df).transform(df)\n",
    "\n",
    "#reg_tipologia\n",
    "indexer = StringIndexer(inputCol=\"reg_tipologia\", outputCol=\"reg_tipologia_indexed\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"reg_tipologia_indexed\", outputCol=\"reg_tipologia_onehot\")\n",
    "df = encoder.fit(df).transform(df)\n",
    "\n",
    "#reg_hierarquia\n",
    "indexer = StringIndexer(inputCol=\"reg_hierarquia\", outputCol=\"reg_hierarquia_indexed\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"reg_hierarquia_indexed\", outputCol=\"reg_hierarquia_onehot\")\n",
    "df = encoder.fit(df).transform(df)\n",
    "\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "#df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9578ed7-1e14-47e2-9844-349fb6f6d201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- prod_ncm: integer (nullable = true)\n",
      " |-- prod_unid: string (nullable = true)\n",
      " |-- prod_quant: double (nullable = true)\n",
      " |-- prod_valor_unit: decimal(15,2) (nullable = true)\n",
      " |-- reg_mesoregiao: string (nullable = true)\n",
      " |-- reg_tipologia: string (nullable = true)\n",
      " |-- reg_hierarquia: string (nullable = true)\n",
      " |-- reg_pop: double (nullable = true)\n",
      " |-- reg_pib: double (nullable = true)\n",
      " |-- prod_unid_indexed: double (nullable = false)\n",
      " |-- prod_unid_onehot: vector (nullable = true)\n",
      " |-- reg_mesoregiao_indexed: double (nullable = false)\n",
      " |-- reg_mesoregiao_onehot: vector (nullable = true)\n",
      " |-- reg_tipologia_indexed: double (nullable = false)\n",
      " |-- reg_tipologia_onehot: vector (nullable = true)\n",
      " |-- reg_hierarquia_indexed: double (nullable = false)\n",
      " |-- reg_hierarquia_onehot: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f89946d-4584-4101-a4c9-3a5e12f7d378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- prod_ncm: integer (nullable = true)\n",
      " |-- prod_unid: vector (nullable = true)\n",
      " |-- prod_quant: double (nullable = true)\n",
      " |-- prod_valor_unit: decimal(15,2) (nullable = true)\n",
      " |-- reg_mesoregiao: vector (nullable = true)\n",
      " |-- reg_tipologia: vector (nullable = true)\n",
      " |-- reg_hierarquia: vector (nullable = true)\n",
      " |-- reg_pop: double (nullable = true)\n",
      " |-- reg_pib: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "columns_to_keep = '''\n",
    "prod_ncm,\n",
    "prod_unid_onehot as prod_unid,\n",
    "prod_quant,\n",
    "prod_valor_unit,\n",
    "reg_mesoregiao_onehot as reg_mesoregiao,\n",
    "reg_tipologia_onehot as reg_tipologia,\n",
    "reg_hierarquia_onehot as reg_hierarquia,\n",
    "reg_pop,\n",
    "reg_pib\n",
    "'''\n",
    "\n",
    "df = spark.sql(f\"SELECT {columns_to_keep} FROM df\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7bef5ff5-a3eb-4ff9-8956-4c5773ac4aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------+---------------+--------------+-------------+--------------+-------------------+-------------------+\n",
      "|prod_ncm|    prod_unid|          prod_quant|prod_valor_unit|reg_mesoregiao|reg_tipologia|reg_hierarquia|            reg_pop|            reg_pib|\n",
      "+--------+-------------+--------------------+---------------+--------------+-------------+--------------+-------------------+-------------------+\n",
      "|30049059|(4,[0],[1.0])| -0.8904793211295619|          47.84|(36,[5],[1.0])|    (2,[],[])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|30049059|(4,[0],[1.0])| -0.8904793211295619|          47.84|(36,[5],[1.0])|    (2,[],[])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|30049059|(4,[0],[1.0])|-0.25442384791357503|          13.83|(36,[5],[1.0])|    (2,[],[])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])|   0.850702099178969|           1.18|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])| -0.3100855143600515|           1.18|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|44211000|(4,[0],[1.0])| -0.3100855143600515|           0.79|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])| 0.34329273076357997|           1.18|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])| 0.43676473021423873|           0.89|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])|  0.7344440194652196|           1.18|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])|  1.3308480578155166|           1.22|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|44211000|(4,[0],[1.0])| -0.4428542256065747|           0.79|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])|  0.7008900644364014|           0.89|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])|   0.490996633379883|           0.89|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])|   0.490996633379883|           1.22|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])| 0.43676473021423873|           0.89|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])|   0.490996633379883|           0.89|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])| 0.34329273076357997|           1.18|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])| 0.34329273076357997|           1.18|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])| -0.8904793211295619|          14.30|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "|21069010|(4,[0],[1.0])|-0.00612224198112...|           1.18|(36,[5],[1.0])|(2,[0],[1.0])|(13,[0],[1.0])|-1.2079660195805064|-1.6211221394492155|\n",
      "+--------+-------------+--------------------+---------------+--------------+-------------+--------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2fc5d899-0af4-4eaf-88f1-9e9add0439eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f67aa955-5bef-4b6c-a402-b983efcc2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"prod_ncm\", \"prod_unid\", \"prod_quant\", \"reg_mesoregiao\", \"reg_tipologia\", \"reg_hierarquia\", \"reg_pop\", \"reg_pib\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "df_lr = assembler.transform(df)\n",
    "final_df = df_lr.select(\"features\", \"prod_valor_unit\")\n",
    "\n",
    "train_df, test_df = final_df.randomSplit([0.8, 0.2], seed=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0e4c013-05ba-4577-a549-ef55c208408d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 20:39:30 WARN Instrumentation: [879ecefb] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/06/11 20:39:47 WARN Instrumentation: [879ecefb] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "linear_regressor = LinearRegression(featuresCol=\"features\", labelCol=\"prod_valor_unit\", predictionCol=\"predicted_prod_valor_unit_lr\")\n",
    "linear_regressor_model = linear_regressor.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f9c6932-7872-411b-8002-dfa1d7f1b511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data: 1841.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2) on test data: -0.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions_lr = linear_regressor_model.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"prod_valor_unit\", predictionCol=\"predicted_prod_valor_unit_lr\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions_lr)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data: {:.3f}\".format(rmse))\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"prod_valor_unit\", predictionCol=\"predicted_prod_valor_unit_lr\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions_lr)\n",
    "print(\"R-squared (R2) on test data: {:.3f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20782c69-3de9-47e4-8f1b-9f5668f113ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9d92ebf-4ee1-46ed-aa5e-aad98f5080f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"prod_ncm\", \"prod_unid\", \"prod_quant\", \"reg_mesoregiao\", \"reg_tipologia\", \"reg_hierarquia\", \"reg_pop\", \"reg_pib\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "df_dt = assembler.transform(df)\n",
    "final_df = df_dt.select(\"features\", \"prod_valor_unit\")\n",
    "\n",
    "train_df, test_df = final_df.randomSplit([0.8, 0.2], seed=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3ea7029-fc11-4f98-977c-faf1b961f663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 20:41:26 WARN MemoryStore: Not enough space to cache rdd_165_0 in memory! (computed 228.0 MiB so far)\n",
      "24/06/11 20:41:26 WARN BlockManager: Persisting block rdd_165_0 to disk instead.\n",
      "24/06/11 20:41:32 WARN MemoryStore: Not enough space to cache rdd_165_0 in memory! (computed 333.4 MiB so far)\n",
      "24/06/11 20:41:37 WARN MemoryStore: Not enough space to cache rdd_165_0 in memory! (computed 333.4 MiB so far)\n",
      "24/06/11 20:41:40 WARN MemoryStore: Not enough space to cache rdd_165_0 in memory! (computed 333.4 MiB so far)\n",
      "24/06/11 20:41:43 WARN MemoryStore: Not enough space to cache rdd_165_0 in memory! (computed 333.4 MiB so far)\n",
      "24/06/11 20:41:47 WARN MemoryStore: Not enough space to cache rdd_165_0 in memory! (computed 333.4 MiB so far)\n",
      "24/06/11 20:41:51 WARN MemoryStore: Not enough space to cache rdd_165_0 in memory! (computed 333.4 MiB so far)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tree_regressor = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"prod_valor_unit\", predictionCol=\"predicted_prod_valor_unit_tr\", maxDepth=6)\n",
    "tree_regressor_model = tree_regressor.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9857934f-9d36-4175-8fc0-6ebde6ea6bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data: 1745.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2) on test data: 0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions_tr = tree_regressor_model.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"prod_valor_unit\", predictionCol=\"predicted_prod_valor_unit_tr\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions_tr)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data: {:.3f}\".format(rmse))\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"prod_valor_unit\", predictionCol=\"predicted_prod_valor_unit_tr\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions_tr)\n",
    "print(\"R-squared (R2) on test data: {:.3f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b512151f-4abe-496f-a5e0-10d677803e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'prod_ncm': 0.30816962196917363\n",
      "Feature 'prod_unid': 0.38948853011610995\n",
      "Feature 'prod_quant': 0.0\n",
      "Feature 'reg_mesoregiao': 3.90186018602796e-09\n",
      "Feature 'reg_tipologia': 6.3373854783343774e-09\n",
      "Feature 'reg_hierarquia': 0.00588278450807791\n",
      "Feature 'reg_pop': 0.0\n",
      "Feature 'reg_pib': 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_importance = tree_regressor_model.featureImportances.toArray()\n",
    "\n",
    "# Show feature importance\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f\"Feature '{column}': {feature_importance[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4c92e3c-a1a4-445d-b8c7-718a8d0f3266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "  prod_valor_unit: 404.825\n",
      "  reg_mesoregiao: 299.325\n",
      "  prod_quant: 196.284\n",
      "  reg_pop: 182.820\n",
      "  reg_tipologia: 170.132\n",
      "  reg_pib: 140.004\n",
      "  prod_unid: 77.906\n",
      "  reg_hierarquia: 37.121\n",
      "  prod_ncm: 0.000\n"
     ]
    }
   ],
   "source": [
    "coefficients = linear_regressor_model.coefficients\n",
    "intercept = linear_regressor_model.intercept\n",
    "\n",
    "feature_importance_lr = sorted(list(zip(df_lr.columns[:-1], map(abs, coefficients))), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "for feature, importance in feature_importance_lr:\n",
    "    print(\"  {}: {:.3f}\".format(feature, importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ec816d3-b4b0-46ba-b017-b86c72a40f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe972865-c2ec-44b4-81c0-e6983bcd109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"prod_ncm\", \"prod_unid\", \"prod_quant\", \"reg_mesoregiao\", \"reg_tipologia\", \"reg_hierarquia\", \"reg_pop\", \"reg_pib\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "df_rf = assembler.transform(df)\n",
    "final_df = df_rf.select(\"features\", \"prod_valor_unit\")\n",
    "\n",
    "train_df, test_df = final_df.randomSplit([0.8, 0.2], seed=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c84d8401-4a97-4ab2-97f5-22960072bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 20:51:51 WARN MemoryStore: Not enough space to cache rdd_266_0 in memory! (computed 215.0 MiB so far)\n",
      "24/06/11 20:51:51 WARN BlockManager: Persisting block rdd_266_0 to disk instead.\n",
      "24/06/11 20:52:02 WARN MemoryStore: Not enough space to cache rdd_266_0 in memory! (computed 323.2 MiB so far)\n",
      "24/06/11 20:52:16 WARN MemoryStore: Not enough space to cache rdd_266_0 in memory! (computed 323.2 MiB so far)\n",
      "24/06/11 20:52:30 WARN MemoryStore: Not enough space to cache rdd_266_0 in memory! (computed 323.2 MiB so far)\n",
      "24/06/11 20:52:48 WARN MemoryStore: Not enough space to cache rdd_266_0 in memory! (computed 323.2 MiB so far)\n",
      "24/06/11 20:53:05 WARN MemoryStore: Not enough space to cache rdd_266_0 in memory! (computed 323.2 MiB so far)\n",
      "24/06/11 20:53:24 WARN MemoryStore: Not enough space to cache rdd_266_0 in memory! (computed 323.2 MiB so far)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "forest_regressor = RandomForestRegressor(featuresCol=\"features\", labelCol=\"prod_valor_unit\", predictionCol=\"predicted_prod_valor_unit_fr\", maxDepth=6, numTrees=30)\n",
    "forest_regressor_model = forest_regressor.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "270f2fed-dd52-4639-8413-d6c45a65b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data: 2144.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2) on test data: -0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions_fr = forest_regressor_model.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"prod_valor_unit\", predictionCol=\"predicted_prod_valor_unit_fr\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions_fr)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data: {:.3f}\".format(rmse))\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"prod_valor_unit\", predictionCol=\"predicted_prod_valor_unit_fr\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions_fr)\n",
    "print(\"R-squared (R2) on test data: {:.3f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a933da77-e90a-4b9c-9da1-b2825b666426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'prod_ncm': 0.24918984233367159\n",
      "Feature 'prod_unid': 0.12955840114910877\n",
      "Feature 'prod_quant': 0.001192668422601933\n",
      "Feature 'reg_mesoregiao': 0.006460549498743054\n",
      "Feature 'reg_tipologia': 0.01868965460921217\n",
      "Feature 'reg_hierarquia': 0.26186274276227167\n",
      "Feature 'reg_pop': 1.411897577173017e-06\n",
      "Feature 'reg_pib': 3.773560017182131e-05\n"
     ]
    }
   ],
   "source": [
    "feature_importance = forest_regressor_model.featureImportances.toArray()\n",
    "\n",
    "# Show feature importance\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f\"Feature '{column}': {feature_importance[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aea5581e-3a28-4d0b-8bf3-8fafc55c5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
